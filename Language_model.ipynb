{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ffdd2f8",
   "metadata": {},
   "source": [
    "# Language Model\n",
    "Implementation of a language model using n-gram language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255aa388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0de4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLM():\n",
    "    # Implementeer hier je BigramLM klasse\n",
    "    def __init__(self, vocabulary, language):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.n = len(vocabulary)\n",
    "        self.dataTable = pd.DataFrame()\n",
    "        self.numpyTable = np.ones((self.n, self.n), dtype=int)\n",
    "        self.charsCount = dict()\n",
    "        self.charToInt = dict()\n",
    "        self.language = language\n",
    "        self.probsTable = pd.DataFrame(0.0, index=self.vocabulary, columns=self.vocabulary)\n",
    "        self.getIntsForChars()\n",
    "    \n",
    "    def train(self, trainSet):\n",
    "        \"\"\"Trains the bigram model on the training set\"\"\"\n",
    "        self.getTokensCount(trainSet) # Compute the counts for each token\n",
    "        self.getBigramCounts(trainSet) # Compute the bigram counts\n",
    "        self.getLogProbsFromCounts() # Compute from the counts the log probs\n",
    "        self.getCumulatedProbsTable() # Compute the cumulated probs table for sampling\n",
    "        \n",
    "    def getTokensCount(self, trainSet): # Correct\n",
    "        \"\"\"Compute the count dictionary that holds a count for all chars\"\"\"\n",
    "        for char in trainSet:\n",
    "            if char in self.charsCount:\n",
    "                self.charsCount[char] += 1\n",
    "            else:\n",
    "                self.charsCount[char] = 1\n",
    "\n",
    "    def getBigramCounts(self, trainset):\n",
    "        \"\"\"Computes the bigram table that holds the counts for each entry\"\"\"\n",
    "        # Use numpy tables for this step. It is a lot faster.\n",
    "        prevCharIntValue = self.charToInt[' ']\n",
    "        for char in trainset:\n",
    "            charIntValue = self.charToInt[char]\n",
    "            self.numpyTable[prevCharIntValue][charIntValue] += 1\n",
    "            prevCharIntValue = charIntValue\n",
    "        # Transform the numpy table into a pandas table\n",
    "        self.dataTable = pd.DataFrame(self.numpyTable, index=self.vocabulary, columns=self.vocabulary, dtype=float)\n",
    "\n",
    "    def getLogProbsFromCounts(self):\n",
    "        \"\"\"Computes the probabilities from the counts table\"\"\"\n",
    "        for rowChar in self.dataTable.index:\n",
    "            for colChar in self.dataTable.columns:\n",
    "                countColCharAfterRowChar = self.dataTable.at[rowChar, colChar]\n",
    "                countRowChar = self.charsCount[rowChar]\n",
    "                prob = countColCharAfterRowChar / (countRowChar + self.n) # Add the size of the vocabulary for the smoothing\n",
    "                self.probsTable.at[rowChar, colChar] = prob\n",
    "                logProb = math.log(prob)\n",
    "                self.dataTable.at[rowChar, colChar] = logProb\n",
    "\n",
    "    def getIntsForChars(self):\n",
    "        \"\"\"Map all chars from vocabulary to integers\"\"\"\n",
    "        counter = 0\n",
    "        for char in self.vocabulary:\n",
    "            self.charToInt[char] = counter\n",
    "            counter += 1\n",
    "\n",
    "    def perplexity(self, testSet):\n",
    "        \"\"\"Computes the perplexity for the given testSet\"\"\"\n",
    "        perplexity = 0\n",
    "        prevChar = ' '\n",
    "        for char in testSet:\n",
    "            perplexity += self.dataTable.at[prevChar, char]\n",
    "            prevChar = char\n",
    "        \n",
    "        perplexity /= len(testSet)\n",
    "        perplexity = math.exp(-perplexity)\n",
    "        return perplexity\n",
    "\n",
    "    def getCumulatedProbsTable(self):\n",
    "        \"\"\"Compute a special probs table that will get at each column the prob\n",
    "        from current col and all the cols before, added to it.\"\"\"\n",
    "        for rowChar in self.probsTable.index:\n",
    "            prevColProb = 0\n",
    "            for colChar in self.probsTable.columns:\n",
    "                colProb = self.probsTable.at[rowChar, colChar]\n",
    "                self.probsTable.at[rowChar, colChar] = prevColProb + colProb\n",
    "                prevColProb += colProb\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Function that generates text\"\"\"\n",
    "        rowChar = r.choice(self.vocabulary) # Pick a random char to begin the generation with\n",
    "        outputSentence = [rowChar]\n",
    "        LENGTH_GEN_TEXT = 100\n",
    "        currLength = 1\n",
    "        while (currLength < LENGTH_GEN_TEXT):\n",
    "            randNum = int.from_bytes(os.urandom(8), byteorder=\"big\") / ((1 << 64) - 1)\n",
    "            for colChar in self.probsTable.columns:\n",
    "                if self.probsTable.at[rowChar, colChar] > randNum:\n",
    "                    outputSentence.append(colChar)\n",
    "                    rowChar = colChar\n",
    "                    break\n",
    "\n",
    "            currLength += 1\n",
    "        result = ''.join(outputSentence)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96d61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files and build the vocabularies\n",
    "dutchFile = open('corpora/corpora/nld_news_2020-sentences.txt', 'r', encoding='utf-8').read()\n",
    "dutchVocabulary = sorted(set(dutchFile))\n",
    "\n",
    "basqueFile = open('corpora/corpora/eus_news_2020-sentences.txt', 'r', encoding='utf-8').read()\n",
    "basqueVocabulary = sorted(set(basqueFile))\n",
    "    \n",
    "turkishFile = open('corpora/corpora/tur_news_2020-sentences.txt', 'r', encoding='utf-8').read()\n",
    "turkishVocabulary = sorted(set(turkishFile))\n",
    "\n",
    "dutch_model = BigramLM(dutchVocabulary, 'dutch')\n",
    "dutch_model.train(dutchFile)\n",
    "\n",
    "basque_model = BigramLM(basqueVocabulary, 'basque')\n",
    "basque_model.train(basqueFile)\n",
    "\n",
    "turkish_model = BigramLM(turkishVocabulary, 'turkish')\n",
    "turkish_model.train(turkishFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ffa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basque'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listModels = [dutch_model, basque_model, turkish_model]\n",
    "\n",
    "# Identify language based on the perplexity for each model\n",
    "def identify_language(sentence):\n",
    "    language = \"None\"\n",
    "    currMin = float('inf')\n",
    "    for model in listModels:\n",
    "        currPerplexity = model.perplexity(sentence)\n",
    "        if currPerplexity < currMin:\n",
    "            currMin = currPerplexity\n",
    "            language = model.language\n",
    "    \n",
    "    return language\n",
    "    \n",
    "\n",
    "identify_language(\"kaixo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2677ea55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basque\n",
      "dutch\n"
     ]
    }
   ],
   "source": [
    "# Test identify language feature\n",
    "print(identify_language(\"kaixo\"))\n",
    "print(identify_language(\"Wiskunde is moeilijk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f95517fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n emurreniagikozurtxupo ezerrribieneko enguz heko le a ma lar e beakonda Jrasti duk Osta COKe ekaizh\n"
     ]
    }
   ],
   "source": [
    "# Generate text in basque\n",
    "basque_model.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94288d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pen he t eroe eeetenovarelachoprgooger.\n",
      "Iket be von mogs slaudjkun, om.\n",
      "VDar.\n",
      "Alie jntene vaabe bete\n"
     ]
    }
   ],
   "source": [
    "# Generate text in dutch\n",
    "dutch_model.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3159fc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uzati bike göncergöyelanera kumığran ön Avaririzdünisi.\n",
      "Olev'din ve 3.\n",
      "Araparosiliçosır biti\"\n",
      "Özadek\n"
     ]
    }
   ],
   "source": [
    "# Generate text in turkish\n",
    "turkish_model.sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
